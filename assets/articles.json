{
    "last_month": [
        {
            "title": "Probabilistic Forecasting for Dynamical Systems with Missing or Imperfect Data",
            "year": "March 2025",
            "date": "2025-03-15",
            "authors": "Siddharth Rout, Eldad Haber, Stéphane Gaudreault",
            "abstract": "The modeling of dynamical systems is essential in many fields, but applying\nmachine learning techniques is often challenging due to incomplete or noisy\ndata. This study introduces a variant of stochastic interpolation (SI) for\nprobabilistic forecasting, estimating future states as distributions rather\nthan single-point predictions. We explore its mathematical foundations and\ndemonstrate its effectiveness on various dynamical systems, including the\nchallenging WeatherBench dataset.",
            "link": "http://arxiv.org/pdf/2503.12273v1"
        },
        {
            "title": "Deep Learning of the Evolution Operator Enables Forecasting of Out-of-Training Dynamics in Chaotic Systems",
            "year": "February 2025",
            "date": "2025-02-28",
            "authors": "Ira J. S. Shokar, Peter H. Haynes, Rich R. Kerswell",
            "abstract": "We demonstrate that a deep learning emulator for chaotic systems can forecast\nphenomena absent from training data. Using the Kuramoto-Sivashinsky and\nbeta-plane turbulence models, we evaluate the emulator through scenarios\nprobing the fundamental phenomena of both systems: forecasting spontaneous\nrelaminarisation, capturing initialisation of arbitrary chaotic states,\nzero-shot prediction of dynamics with parameter values outside of the training\nrange, and characterisation of dynamical statistics from artificially\nrestricted training datasets. Our results show that deep learning emulators can\nuncover emergent behaviours and rare events in complex systems by learning\nunderlying mathematical rules, rather than merely mimicking observed patterns.",
            "link": "http://arxiv.org/pdf/2502.20603v1"
        },
        {
            "title": "Anderson localized states for the nonlinear Maryland model on \\(\\mathbb{Z}^d\\)",
            "year": "February 2025",
            "date": "2025-02-23",
            "authors": "Shihe Liu, Yunfeng Shi, Zhifei Zhang",
            "abstract": "In this paper, we investigate Anderson localization for a nonlinear\nperturbation of the Maryland model\n\\(H=\\varepsilon\\Delta+\\cot\\pi(\\theta+j\\cdot\\alpha)\\delta_{j,j'}\\) on\n\\(\\mathbb{Z}^d\\). Specifically, if \\(\\varepsilon,\\delta\\) are sufficiently small,\nwe construct a large number of time quasi-periodic and space exponentially\ndecaying solutions (i.e., Anderson localized states) for the equation\n\\(i\\frac{\\partial u}{\\partial t}=Hu+\\delta|u|^{2p}u\\) with a Diophantine\n\\(\\alpha\\). Our proof combines eigenvalue estimates of the Maryland model with\nthe Craig-Wayne-Bourgain method, which originates from KAM theory for\nHamiltonian PDEs.",
            "link": "http://arxiv.org/pdf/2502.16397v1"
        },
        {
            "title": "Computer-Assisted Proofs of Solitons in Bose-Einstein Condensates",
            "year": "March 2025",
            "date": "2025-03-06",
            "authors": "Miguel Ayala, Carlos García-Azpeitia, Jean-Philippe Lessard",
            "abstract": "We rigorously prove the existence of gap solitons in the one-dimensional\nGross-Pitaevskii (GP) equation with a periodic potential. These nonlinear\nlocalized solutions emerge in spectral gaps and play a crucial role in\nunderstanding Bose-Einstein condensates (BECs). To prove them, we reformulate\nthe problem as the search for homoclinic orbits in a higher-dimensional\ndynamical system. We then use computer-assisted proof techniques, combined with\na functional analytic framework, to rigorously validate numerically\napproximated homoclinic orbits. This work bridges computational evidence and\nformal mathematical proofs, providing a solid foundation for the study of\nsolitons in the GP equation.",
            "link": "http://arxiv.org/pdf/2503.04701v1"
        },
        {
            "title": "Cross-Modal Diffusion for Biomechanical Dynamical Systems Through Local Manifold Alignment",
            "year": "March 2025",
            "date": "2025-03-15",
            "authors": "Sharmita Dey, Sarath Ravindran Nair",
            "abstract": "We present a mutually aligned diffusion framework for cross-modal\nbiomechanical motion generation, guided by a dynamical systems perspective. By\ntreating each modality, e.g., observed joint angles (\\(X\\)) and ground reaction\nforces (\\(Y\\)), as complementary observations of a shared underlying locomotor\ndynamical system, our method aligns latent representations at each diffusion\nstep, so that one modality can help denoise and disambiguate the other. Our\nalignment approach is motivated by the fact that local time windows of \\(X\\) and\n\\(Y\\) represent the same phase of an underlying dynamical system, thereby\nbenefiting from a shared latent manifold. We introduce a simple local latent\nmanifold alignment (LLMA) strategy that incorporates first-order and\nsecond-order alignment within the latent space for robust cross-modal\nbiomechanical generation without bells and whistles. Through experiments on\nmultimodal human biomechanics data, we show that aligning local latent dynamics\nacross modalities improves generation fidelity and yields better\nrepresentations.",
            "link": "http://arxiv.org/pdf/2503.12214v1"
        }
    ],
    "last_year": [
        {
            "title": "Predator Prey Scavenger Model using Holling's Functional Response of Type III and Physics-Informed Deep Neural Networks",
            "year": "December 2024",
            "date": "2024-12-24",
            "authors": "Aneesh Panchal, Kirti Beniwal, Vivek Kumar",
            "abstract": "Nonlinear mathematical models introduce the relation between various physical\nand biological interactions present in nature. One of the most famous models is\nthe Lotka-Volterra model which defined the interaction between predator and\nprey species present in nature. However, predators, scavengers, and prey\npopulations coexist in a natural system where scavengers can additionally rely\non the dead bodies of predators present in the system. Keeping this in mind,\nthe formulation and simulation of the predator prey scavenger model is\nintroduced in this paper. For the predation response, respective prey species\nare assumed to have Holling's functional response of type III. The proposed\nmodel is tested for various simulations and is found to be showing satisfactory\nresults in different scenarios. After simulations, the American forest dataset\nis taken for parameter estimation which imitates the real-world case. For\nparameter estimation, a physics-informed deep neural network is used with the\nAdam backpropagation method which prevents the avalanche effect in trainable\nparameters updation. For neural networks, mean square error and\nphysics-informed informed error are considered. After the neural network, the\nhence-found parameters are fine-tuned using the\nBroyden-Fletcher-Goldfarb-Shanno algorithm. Finally, the hence-found parameters\nusing a natural dataset are tested for stability using Jacobian stability\nanalysis. Future research work includes minimization of error induced by\nparameters, bifurcation analysis, and sensitivity analysis of the parameters.",
            "link": "http://arxiv.org/pdf/2412.18344v1"
        },
        {
            "title": "Reservoir Computing with Generalized Readout based on Generalized Synchronization",
            "year": "May 2024",
            "date": "2024-05-03",
            "authors": "Akane Ookubo, Masanobu Inubushi",
            "abstract": "Reservoir computing is a machine learning framework that exploits nonlinear\ndynamics, exhibiting significant computational capabilities. One of the\ndefining characteristics of reservoir computing is its low cost and\nstraightforward training algorithm, i.e. only the readout, given by a linear\ncombination of reservoir variables, is trained. Inspired by recent mathematical\nstudies based on dynamical system theory, in particular generalized\nsynchronization, we propose a novel reservoir computing framework with\ngeneralized readout, including a nonlinear combination of reservoir variables.\nThe first crucial advantage of using the generalized readout is its\nmathematical basis for improving information processing capabilities. Secondly,\nit is still within a linear learning framework, which preserves the original\nstrength of reservoir computing. In summary, the generalized readout is\nnaturally derived from mathematical theory and allows the extraction of useful\nbasis functions from reservoir dynamics without sacrificing simplicity. In a\nnumerical study, we find that introducing the generalized readout leads to a\nsignificant improvement in accuracy and an unexpected enhancement in robustness\nfor the short- and long-term prediction of Lorenz chaos, with a particular\nfocus on how to harness low-dimensional reservoir dynamics. A novel way and its\nadvantages for physical implementations of reservoir computing with generalized\nreadout are briefly discussed.",
            "link": "http://arxiv.org/pdf/2405.14885v1"
        },
        {
            "title": "ADAM-SINDy: An Efficient Optimization Framework for Parameterized Nonlinear Dynamical System Identification",
            "year": "October 2024",
            "date": "2024-10-21",
            "authors": "Siva Viknesh, Younes Tatari, Amirhossein Arzani",
            "abstract": "Identifying dynamical systems characterized by nonlinear parameters presents\nsignificant challenges in deriving mathematical models that enhance\nunderstanding of physics. Traditional methods, such as Sparse Identification of\nNonlinear Dynamics (SINDy) and symbolic regression, can extract governing\nequations from observational data; however, they also come with distinct\nadvantages and disadvantages. This paper introduces a novel method within the\nSINDy framework, termed ADAM-SINDy, which synthesizes the strengths of\nestablished approaches by employing the ADAM optimization algorithm. This\nfacilitates the simultaneous optimization of nonlinear parameters and\ncoefficients associated with nonlinear candidate functions, enabling precise\nparameter estimation without requiring prior knowledge of nonlinear\ncharacteristics such as trigonometric frequencies, exponential bandwidths, or\npolynomial exponents, thereby addressing a key limitation of SINDy. Through an\nintegrated global optimization, ADAM-SINDy dynamically adjusts all unknown\nvariables in response to data, resulting in an adaptive identification\nprocedure that reduces the sensitivity to the library of candidate functions.\nThe performance of the ADAM-SINDy methodology is demonstrated across a spectrum\nof dynamical systems, including benchmark coupled nonlinear ordinary\ndifferential equations such as oscillators, chaotic fluid flows, reaction\nkinetics, pharmacokinetics, as well as nonlinear partial differential equations\n(wildfire transport). The results demonstrate significant improvements in\nidentifying parameterized dynamical systems and underscore the importance of\nconcurrently optimizing all parameters, particularly those characterized by\nnonlinear parameters. These findings highlight the potential of ADAM-SINDy to\nextend the applicability of the SINDy framework in addressing more complex\nchallenges in dynamical system identification.",
            "link": "http://arxiv.org/pdf/2410.16528v2"
        },
        {
            "title": "Generalization of the Painlevé Property and Existence and Uniqueness in Fractional Differential Equations",
            "year": "November 2024",
            "date": "2024-11-28",
            "authors": "Michał Fiedorowicz",
            "abstract": "In this paper, the Painlev\\'e property to fractional differential equations\n(FDEs) are extended and the existence and uniqueness theorems for both linear\nand nonlinear FDEs are established. The results contribute to the research of\nintegrability and solvability in the context of fractional calculus, which has\nsignificant implications in various fields such as physics, engineering, and\napplied sciences. By bridging the gap between pure mathematical theory and\npractical applications, this work provides a foundational understanding that\ncan be utilized in modeling phenomena exhibiting memory and hereditary\nproperties.",
            "link": "http://arxiv.org/pdf/2411.19411v1"
        },
        {
            "title": "Clustering in pure-attention hardmax transformers and its role in sentiment analysis",
            "year": "June 2024",
            "date": "2024-06-26",
            "authors": "Albert Alcalde, Giovanni Fantuzzi, Enrique Zuazua",
            "abstract": "Transformers are extremely successful machine learning models whose\nmathematical properties remain poorly understood. Here, we rigorously\ncharacterize the behavior of transformers with hardmax self-attention and\nnormalization sublayers as the number of layers tends to infinity. By viewing\nsuch transformers as discrete-time dynamical systems describing the evolution\nof points in a Euclidean space, and thanks to a geometric interpretation of the\nself-attention mechanism based on hyperplane separation, we show that the\ntransformer inputs asymptotically converge to a clustered equilibrium\ndetermined by special points called leaders. We then leverage this theoretical\nunderstanding to solve sentiment analysis problems from language processing\nusing a fully interpretable transformer model, which effectively captures\n`context' by clustering meaningless words around leader words carrying the most\nmeaning. Finally, we outline remaining challenges to bridge the gap between the\nmathematical analysis of transformers and their real-life implementation.",
            "link": "http://arxiv.org/pdf/2407.01602v1"
        }
    ],
    "last_5_years": [
        {
            "title": "A mathematical perspective on Transformers",
            "year": "December 2023",
            "date": "2023-12-17",
            "authors": "Borjan Geshkovski, Cyril Letrouit, Yury Polyanskiy, Philippe Rigollet",
            "abstract": "Transformers play a central role in the inner workings of large language\nmodels. We develop a mathematical framework for analyzing Transformers based on\ntheir interpretation as interacting particle systems, which reveals that\nclusters emerge in long time. Our study explores the underlying theory and\noffers new perspectives for mathematicians as well as computer scientists.",
            "link": "http://arxiv.org/pdf/2312.10794v4"
        },
        {
            "title": "Coupled and Uncoupled Dynamic Mode Decomposition in Multi-Compartmental Systems with Applications to Epidemiological and Additive Manufacturing Problems",
            "year": "October 2021",
            "date": "2021-10-12",
            "authors": "Alex Viguerie, Gabriel F. Barros, Malú Grave, Alessandro Reali, Alvaro L. G. A. Coutinho",
            "abstract": "Dynamic Mode Decomposition (DMD) is an unsupervised machine learning method\nthat has attracted considerable attention in recent years owing to its\nequation-free structure, ability to easily identify coherent spatio-temporal\nstructures in data, and effectiveness in providing reasonably accurate\npredictions for certain problems. Despite these successes, the application of\nDMD to certain problems featuring highly nonlinear transient dynamics remains\nchallenging. In such cases, DMD may not only fail to provide acceptable\npredictions but may indeed fail to recreate the data in which it was trained,\nrestricting its application to diagnostic purposes. For many problems in the\nbiological and physical sciences, the structure of the system obeys a\ncompartmental framework, in which the transfer of mass within the system moves\nwithin states. In these cases, the behavior of the system may not be accurately\nrecreated by applying DMD to a single quantity within the system, as proper\nknowledge of the system dynamics, even for a single compartment, requires that\nthe behavior of other compartments is taken into account in the DMD process. In\nthis work, we demonstrate, theoretically and numerically, that, when performing\nDMD on a fully coupled PDE system with compartmental structure, one may recover\nuseful predictive behavior, even when DMD performs poorly when acting\ncompartment-wise. We also establish that important physical quantities, as mass\nconservation, are maintained in the coupled-DMD extrapolation. The mathematical\nand numerical analysis suggests that DMD may be a powerful tool when applied to\nthis common class of problems. In particular, we show interesting numerical\napplications to a continuous delayed-SIRD model for Covid-19, and to a problem\nfrom additive manufacturing considering a nonlinear temperature field and the\nresulting change of material phase from powder, liquid, and solid states.",
            "link": "http://arxiv.org/pdf/2110.06375v1"
        },
        {
            "title": "Some open problems in low dimensional dynamical systems",
            "year": "December 2020",
            "date": "2020-12-04",
            "authors": "Armengol Gasull",
            "abstract": "The aim of this paper is to share with the mathematical community a list of\n33 problems that I have found along the years during my research. I believe\nthat it is worth to think about them and, hopefully, it will be possible either\nto solve some of the problems or to make some substantial progress. Many of\nthem are about planar differential equations but there are also questions about\nother mathematical aspects: Abel differential equations, difference equations,\nglobal asymptotic stability, geometrical questions, problems involving\npolynomials or some recreational problems with a dynamical component.",
            "link": "http://arxiv.org/pdf/2012.02524v1"
        },
        {
            "title": "On Neural Differential Equations",
            "year": "February 2022",
            "date": "2022-02-04",
            "authors": "Patrick Kidger",
            "abstract": "The conjoining of dynamical systems and deep learning has become a topic of\ngreat interest. In particular, neural differential equations (NDEs) demonstrate\nthat neural networks and differential equation are two sides of the same coin.\nTraditional parameterised differential equations are a special case. Many\npopular neural network architectures, such as residual networks and recurrent\nnetworks, are discretisations.\n  NDEs are suitable for tackling generative problems, dynamical systems, and\ntime series (particularly in physics, finance, ...) and are thus of interest to\nboth modern machine learning and traditional mathematical modelling. NDEs offer\nhigh-capacity function approximation, strong priors on model space, the ability\nto handle irregular data, memory efficiency, and a wealth of available theory\non both sides.\n  This doctoral thesis provides an in-depth survey of the field.\n  Topics include: neural ordinary differential equations (e.g. for hybrid\nneural/mechanistic modelling of physical systems); neural controlled\ndifferential equations (e.g. for learning functions of irregular time series);\nand neural stochastic differential equations (e.g. to produce generative models\ncapable of representing complex stochastic dynamics, or sampling from complex\nhigh-dimensional distributions).\n  Further topics include: numerical methods for NDEs (e.g. reversible\ndifferential equations solvers, backpropagation through differential equations,\nBrownian reconstruction); symbolic regression for dynamical systems (e.g. via\nregularised evolution); and deep implicit models (e.g. deep equilibrium models,\ndifferentiable optimisation).\n  We anticipate this thesis will be of interest to anyone interested in the\nmarriage of deep learning with dynamical systems, and hope it will provide a\nuseful reference for the current state of the art.",
            "link": "http://arxiv.org/pdf/2202.02435v1"
        },
        {
            "title": "Scalable algorithms for physics-informed neural and graph networks",
            "year": "May 2022",
            "date": "2022-05-16",
            "authors": "Khemraj Shukla, Mengjia Xu, Nathaniel Trask, George Em Karniadakis",
            "abstract": "Physics-informed machine learning (PIML) has emerged as a promising new\napproach for simulating complex physical and biological systems that are\ngoverned by complex multiscale processes for which some data are also\navailable. In some instances, the objective is to discover part of the hidden\nphysics from the available data, and PIML has been shown to be particularly\neffective for such problems for which conventional methods may fail. Unlike\ncommercial machine learning where training of deep neural networks requires big\ndata, in PIML big data are not available. Instead, we can train such networks\nfrom additional information obtained by employing the physical laws and\nevaluating them at random points in the space-time domain. Such\nphysics-informed machine learning integrates multimodality and multifidelity\ndata with mathematical models, and implements them using neural networks or\ngraph networks. Here, we review some of the prevailing trends in embedding\nphysics into machine learning, using physics-informed neural networks (PINNs)\nbased primarily on feed-forward neural networks and automatic differentiation.\nFor more complex systems or systems of systems and unstructured data, graph\nneural networks (GNNs) present some distinct advantages, and here we review how\nphysics-informed learning can be accomplished with GNNs based on graph exterior\ncalculus to construct differential operators; we refer to these architectures\nas physics-informed graph networks (PIGNs). We present representative examples\nfor both forward and inverse problems and discuss what advances are needed to\nscale up PINNs, PIGNs and more broadly GNNs for large-scale engineering\nproblems.",
            "link": "http://arxiv.org/pdf/2205.08332v1"
        }
    ],
    "all_time": [
        {
            "title": "A Model of Blood Flow in a Circulation Network",
            "year": "October 2002",
            "date": "2002-10-26",
            "authors": "Weihua Ruan, M. E. Clark, Meide Zhao, Anthony Curcio",
            "abstract": "We study a mathematical model of a blood circulation network which is a\ngeneralization of the coronary model proposed by Smith, Pullan and Hunter. We\nprove the existence and uniqueness of the solution to the initial-boundary\nvalue problem and discuss the continuity of dependence of the solution and its\nderivatives on initial, boundary and forcing functions and their derivatives.",
            "link": "http://arxiv.org/pdf/math/0210410v1"
        },
        {
            "title": "Modeling the influence of TH1 and TH2 type cells in autoimmune diseases",
            "year": "June 2000",
            "date": "2000-06-19",
            "authors": "Y. Louzoun, H. Atlan, I. R. Cohen",
            "abstract": "A sharp TH1/TH2 dichotomy has often been used to define the effects of\ncytokines on autoimmune diseases. However contradictory results in recent\nresearch indicate that the situation may be more complex. We build here a\nsimple mathematical model aimed at settling the contradictions. The model is\nbased on a neural network paradigm, and is applied using Partial Differential\nEquations (PDE). We show here that a TH1/TH2 paradigm is only an external view\nof a complex multivariate system.",
            "link": "http://arxiv.org/pdf/math/0006127v1"
        },
        {
            "title": "Gain-induced oscillations in blood pressure",
            "year": "August 1997",
            "date": "1997-08-16",
            "authors": "Roselyn M. Abbiw-Jackson, William Langford",
            "abstract": "\"Mayer waves\" are long-period (6 to 12 seconds) oscillations in arterial\nblood pressure, which have been observed and studied for more than 100 years in\nthe cardiovascular system of humans and other mammals. A mathematical model of\nthe human cardiovascular system is presented, incorporating parameters\nrelevantto the onset of Mayer waves. The model is analyzed using methods of\nLyapunov stability and Hopf bifurcation theory. The analysis shows that\nincrease in the gain of the baroreflex feedback loop controlling venous volume\nmay lead to the onset of oscillations, while changes in the other parameters\nconsidered do not affect stability of the equilibrium state. The results agree\nwith clinical observations of Mayer waves in human subjects, both in the period\nof the oscillations and in the observed age-dependence of Mayer waves. This\nleads to a proposed explanation of their occurrence, namely that Mayer waves\nare a \"gain-induced instability\".",
            "link": "http://arxiv.org/pdf/math/9708211v1"
        },
        {
            "title": "Rhythms of the nervous system: mathematical themes and variations",
            "year": "May 2003",
            "date": "2003-05-01",
            "authors": "Nancy Kopell",
            "abstract": "The nervous system displays a variety of rhythms in both waking and sleep.\nThese rhythms have been closely associated with different behavioral and\ncognitive states, but it is still unknown how the nervous system makes use of\nthese rhythms to perform functionally important tasks. To address those\nquestions, it is first useful to understood in a mechanistic way the origin of\nthe rhythms, their interactions, the signals which create the transitions among\nrhythms, and the ways in which rhythms filter the signals to a network of\nneurons. This talk discusses how dynamical systems have been used to\ninvestigate the origin, properties and interactions of rhythms in the nervous\nsystem. It focuses on how the underlying physiology of the cells and synapses\nof the networks shape the dynamics of the network in different contexts,\nallowing the variety of dynamical behaviors to be displayed by the same\nnetwork. The work is presented using a series of related case studies on\ndifferent rhythms. These case studies are chosen to highlight mathematical\nissues, and suggest further mathematical work to be done. The topics include:\ndifferent roles of excitation and inhibition in creating synchronous assemblies\nof cells, different kinds of building blocks for neural oscillations, and\ntransitions among rhythms. The mathematical issues include reduction of large\nnetworks to low dimensional maps, role of noise, global bifurcations, use of\nprobabilistic formulations.",
            "link": "http://arxiv.org/pdf/math/0305013v1"
        },
        {
            "title": "Destruction of CD4 T Lymphocytes Alone Cannot Account for their Long-term Decrease in AIDS",
            "year": "August 2000",
            "date": "2000-08-07",
            "authors": "Yoram Louzoun, Irun. R. Cohen, Henri Atlan",
            "abstract": "Following previous models describing a quasi steady state (QSS) for the\nevolution of HIV infection and AIDS, we have developed a larger formalism\nsimulating the long-term evolution of the QSS We show that the long-term\nevolution of AIDS cannot be explained by the destruction alone of CD4 T cells,\neither directly or indirectly. The destruction of CD4 T cells can lead only to\na QSS with a lower concentration of CD4 T cells, but CD4 destruction cannot\ngenerate the sustained long-term decrease in T cells leading to AIDS. We here\nsuggest some workable explanations.",
            "link": "http://arxiv.org/pdf/math/0008052v1"
        }
    ]
}